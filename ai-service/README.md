# AI Assistant Service

FastAPI service cung cáº¥p AI Assistant cho portfolio website cá»§a Huynh Duc Anh.

## ğŸš€ TÃ­nh nÄƒng

- **OpenAI Integration**: Sá»­ dá»¥ng GPT models
- **Knowledge Base**: Portfolio-specific knowledge
- **Conversation Management**: LÆ°u trá»¯ vÃ  quáº£n lÃ½ cuá»™c trÃ² chuyá»‡n
- **Fallback Responses**: Hoáº¡t Ä‘á»™ng khi khÃ´ng cÃ³ OpenAI API
- **Real-time API**: RESTful endpoints
- **Health Monitoring**: Service health checks

## ğŸ› ï¸ CÃ´ng nghá»‡

- **FastAPI** - Modern Python web framework
- **OpenAI API** - Language model integration
- **Pydantic** - Data validation
- **Uvicorn** - ASGI server
- **SQLAlchemy** - Database ORM (optional)
- **Python 3.8+** - Runtime

## ğŸ“‹ YÃªu cáº§u

- Python >= 3.8
- pip package manager

## ğŸš€ CÃ i Ä‘áº·t

### 1. Táº¡o virtual environment (khuyÃªn dÃ¹ng)
```bash
cd ai-service
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 3. Cáº¥u hÃ¬nh environment variables
```bash
cp .env.example .env
```

Chá»‰nh sá»­a file `.env`:
```env
FASTAPI_ENV=development
DEBUG=True
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=150
OPENAI_TEMPERATURE=0.7
DATABASE_URL=sqlite:///./ai_assistant.db
ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:5000"]
```

### 4. Cháº¡y service

**Development mode:**
```bash
uvicorn main:app --reload --port 8000
```

**Production mode:**
```bash
uvicorn main:app --port 8000 --workers 4
```

Service sáº½ cháº¡y trÃªn: http://localhost:8000

## ğŸ“š API Documentation

Khi service Ä‘ang cháº¡y, truy cáº­p:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ”— API Endpoints

### Chat API
- `POST /api/chat` - Chat vá»›i AI Assistant
- `GET /api/chat/suggestions` - Láº¥y gá»£i Ã½ conversation
- `POST /api/chat/feedback` - Gá»­i feedback
- `GET /api/chat/health` - Health check chat service

### Conversations API
- `POST /api/conversations` - Táº¡o conversation má»›i
- `GET /api/conversations/{id}` - Láº¥y conversation theo ID
- `GET /api/conversations/{id}/messages` - Láº¥y messages cá»§a conversation
- `GET /api/conversations` - List conversations
- `DELETE /api/conversations/{id}` - XÃ³a conversation
- `PUT /api/conversations/{id}/title` - Cáº­p nháº­t title
- `POST /api/conversations/{id}/archive` - Archive conversation
- `GET /api/conversations/{id}/export` - Export conversation

### Knowledge Base API
- `GET /api/knowledge` - Láº¥y knowledge base
- `GET /api/knowledge/search` - TÃ¬m kiáº¿m knowledge
- `POST /api/knowledge/upload` - Upload knowledge file

### Health & Info
- `GET /health` - Service health status
- `GET /` - API information

## ğŸ’¬ Chat Examples

### Basic Chat
```bash
curl -X POST "http://localhost:8000/api/chat" \
     -H "Content-Type: application/json" \
     -d '{
       "message": "Tell me about your AI projects",
       "context": "portfolio"
     }'
```

### With Conversation ID
```bash
curl -X POST "http://localhost:8000/api/chat" \
     -H "Content-Type: application/json" \
     -d '{
       "message": "What technologies do you use?",
       "conversation_id": "conv_12345",
       "context": "portfolio"
     }'
```

## ğŸ§  Knowledge Base

AI Assistant cÃ³ knowledge base vá»:

- **Personal Info**: TÃªn, title, bio, liÃªn há»‡
- **Skills**: Programming languages, frameworks, tools
- **Experience**: CÃ´ng viá»‡c, vai trÃ², thÃ nh tÃ­ch
- **Projects**: Dá»± Ã¡n AI/ML Ä‘Ã£ thá»±c hiá»‡n
- **Education**: Há»c váº¥n, chá»©ng chá»‰
- **Services**: Dá»‹ch vá»¥ cung cáº¥p

## ğŸ¤– AI Features

### Smart Responses
- Context-aware conversations
- Portfolio-specific knowledge
- Professional tone
- Helpful suggestions

### Fallback System
- Hoáº¡t Ä‘á»™ng khi khÃ´ng cÃ³ OpenAI API
- Keyword-based responses
- Predefined answers cho cÃ¢u há»i thÆ°á»ng gáº·p

### Conversation Management
- Persistent conversation history
- Context preservation
- Message threading
- Export capabilities

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
ai-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ conversations.py # Conversation management
â”‚   â”‚   â””â”€â”€ knowledge.py    # Knowledge base
â”‚   â”œâ”€â”€ core/               # Core configuration
â”‚   â”‚   â”œâ”€â”€ config.py       # Settings
â”‚   â”‚   â””â”€â”€ logger.py       # Logging setup
â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”‚   â””â”€â”€ ai_service.py   # Main AI service
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env.example           # Environment template
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

### Environment Variables

- `FASTAPI_ENV`: Environment (development/production)
- `DEBUG`: Debug mode (True/False)
- `OPENAI_API_KEY`: OpenAI API key
- `OPENAI_MODEL`: Model name (gpt-3.5-turbo, gpt-4)
- `OPENAI_MAX_TOKENS`: Max response tokens
- `OPENAI_TEMPERATURE`: Response creativity (0.0-2.0)
- `ALLOWED_ORIGINS`: CORS allowed origins
- `DATABASE_URL`: Database connection string

### Model Configuration

```python
# OpenAI Models
- gpt-3.5-turbo: Fast, cost-effective
- gpt-4: More capable, higher cost
- gpt-4-turbo: Latest GPT-4 variant

# Parameters
- max_tokens: 50-500 (recommended)
- temperature: 0.3-0.8 (professional responses)
```

## ğŸ” Security

- **API Key Protection**: OpenAI key trong environment
- **CORS Configuration**: Restricted origins
- **Input Validation**: Pydantic models
- **Rate Limiting**: Built-in protection
- **Error Handling**: Secure error responses

## ğŸ“Š Monitoring

### Health Checks
```bash
curl http://localhost:8000/health
```

### Logs
- Application logs trong `logs/ai_service.log`
- Request/response logging
- Error tracking
- Performance metrics

## ğŸš¨ Troubleshooting

### Common Issues

1. **OpenAI API errors**
   ```
   Error: Invalid API key
   Solution: Kiá»ƒm tra OPENAI_API_KEY trong .env
   ```

2. **Dependencies issues**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt --force-reinstall
   ```

3. **Port conflicts**
   ```bash
   # Kiá»ƒm tra port Ä‘ang sá»­ dá»¥ng
   netstat -ano | findstr :8000
   
   # Cháº¡y trÃªn port khÃ¡c
   uvicorn main:app --port 8001
   ```

4. **CORS errors**
   ```
   Error: CORS policy blocked
   Solution: ThÃªm frontend URL vÃ o ALLOWED_ORIGINS
   ```

### Debug Mode

Cháº¡y vá»›i debug Ä‘á»ƒ xem chi tiáº¿t:
```bash
FASTAPI_ENV=development DEBUG=True uvicorn main:app --reload --log-level debug
```

## ğŸ”„ Deployment

### Production Setup
```bash
# Install production dependencies
pip install gunicorn

# Run with Gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000
```

### Docker (Optional)
```dockerfile
FROM python:3.9
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“ˆ Performance

### Optimization Tips
- Sá»­ dá»¥ng connection pooling
- Cache frequent responses
- Optimize OpenAI parameters
- Monitor API usage/costs

### Scaling
- Multiple worker processes
- Load balancing
- Database optimization
- CDN for static content

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á»:
- Email: huynhducanh.ai@gmail.com  
- GitHub Issues: https://github.com/SENULT/Portfolio/issues
- Documentation: http://localhost:8000/docs

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ”® Future Features

- [ ] Vector database integration
- [ ] Multi-language support
- [ ] Voice conversation
- [ ] Advanced analytics
- [ ] Custom model fine-tuning
